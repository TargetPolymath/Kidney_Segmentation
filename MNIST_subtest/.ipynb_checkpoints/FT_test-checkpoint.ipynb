{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "for pd in physical_devices:\n",
    "    print(pd)\n",
    "    \n",
    "    tf.config.experimental.set_memory_growth(pd, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "# x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FT_Kernel(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs, num_freq, dims):\n",
    "        super(FT_Kernel, self).__init__()\n",
    "        self.outputs     = tf.range(num_outputs)\n",
    "        self.frequencies = tf.constant(num_freq)\n",
    "        self.dims        = tf.constant(dims)\n",
    "        self.output_dim  = num_outputs*len(dims)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.im_dim = input_shape[1]\n",
    "        if len(input_shape) == 3:\n",
    "            input_shape = [1]\n",
    "        self.amplitudes = self.add_weight(\"amplitudes\", \n",
    "                                          shape=[int(input_shape[-1]),\n",
    "                                                 self.outputs.shape[0],\n",
    "                                                 2, \n",
    "                                                 self.frequencies],\n",
    "                                          initializer='random_normal',\n",
    "                                          trainable=True)\n",
    "    @tf.function\n",
    "    def get_kernels(self, dim):\n",
    "        \n",
    "        print(\"Running GK against dim\", dim)\n",
    "\n",
    "            \n",
    "        transformed_freq = tf.cast(self.frequencies+1, tf.float32)\n",
    "\n",
    "        basis_linspace = tf.expand_dims(tf.linspace(0.0, np.pi, dim), -1)\n",
    "        # print(\"BL Shape\")\n",
    "        # print(basis_linspace.shape)\n",
    "\n",
    "        # basis_multi = tf.broadcast_to(basis_linspace, [dim, dim])\n",
    "        basis_multi = tf.tile(input=basis_linspace, multiples=[1, dim])\n",
    "        # print(\"BM Shape\")\n",
    "        # print(basis_multi.shape)\n",
    "\n",
    "\n",
    "        basis_transformed = basis_multi * tf.transpose(transformed_freq)\n",
    "        # print(\"BT Shape\")\n",
    "        # print(basis_transformed.shape)\n",
    "\n",
    "\n",
    "        oscillations = tf.sin(basis_transformed)\n",
    "        # print(\"Osc shape\")\n",
    "        # print(oscillations.shape)\n",
    "\n",
    "        # print(\"Single_freq_stack shape\")\n",
    "        # print(self.amplitudes[:, :, 0].shape)\n",
    "\n",
    "        \n",
    "        # Creating oscillations_multi\n",
    "        pre_om_1 = tf.reshape(oscillations, [dim, dim, 1, 1, 1])\n",
    "        oscillations_multi = tf.tile(pre_om_1, [1, 1, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        # oscillations_multi = tf.broadcast_to(oscillations, [dim, dim, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        # print(\"OM Shape\")\n",
    "        # print(oscillations_multi.shape)\n",
    "        \n",
    "        \n",
    "        # Creating amp_multi_h\n",
    "        pre_amh = tf.reshape(self.amplitudes[:, :, 0], [1, 1, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        amp_multi_h = tf.tile(pre_amh, [dim, dim, 1, 1, 1])\n",
    "        # amp_multi_h = tf.broadcast_to(self.amplitudes[:, :, 0], [dim, dim, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Creating amp_multi_v\n",
    "        pre_amv = tf.reshape(self.amplitudes[:, :, 1], [1, 1, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        amp_multi_v = tf.tile(pre_amv, [dim, dim, 1, 1, 1])\n",
    "        # amp_multi_v = tf.broadcast_to(self.amplitudes[:, :, 1], [dim, dim, self.amplitudes.shape[0], self.amplitudes.shape[1], self.amplitudes.shape[3]])\n",
    "        \n",
    "        \n",
    "        # print(\"OA Multi\")\n",
    "        # print(oscillations_multi.shape)\n",
    "        # print(amp_multi_h.shape)\n",
    "\n",
    "        h_contrib = oscillations_multi*amp_multi_h\n",
    "        v_contrib = tf.transpose(oscillations_multi*amp_multi_v, perm=[1, 0, 2, 3, 4])\n",
    "\n",
    "        h_contrib = tf.reduce_sum(h_contrib, axis=-1)\n",
    "        v_contrib = tf.reduce_sum(v_contrib, axis=-1)\n",
    "        # print(\"HV Shapes\")\n",
    "        # print(h_contrib.shape)\n",
    "        # print(v_contrib.shape)\n",
    "\n",
    "        kernel = h_contrib + v_contrib\n",
    "\n",
    "        return kernel\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, input_tensor):\n",
    "        # print(\"Current Amp Shape: \", self.amplitudes.shape)\n",
    "        # print(input_tensor.shape)\n",
    "        rs_input_tensor = tf.reshape(input_tensor, [-1, self.im_dim, self.im_dim, self.amplitudes.shape[0]])\n",
    "        # Prep Result Storage\n",
    "\n",
    "        def get_dim_result(dim):\n",
    "            kernel = self.get_kernels(dim)\n",
    "            dim_result = tf.nn.conv2d(rs_input_tensor, kernel, strides=[1,1,1,1], padding='SAME')\n",
    "            # print(\"Dim Result\")\n",
    "            # print(dim_result.shape)\n",
    "            return dim_result\n",
    "        \n",
    "        # output_tensor = tf.scan(get_dim_result, tf.expand_dims(self.dims, 1)) # Incorrect\n",
    "        output_tensor = tf.map_fn(get_dim_result, self.dims, dtype=tf.float32)\n",
    "        # output_tensor = tf.stack([get_dim_result(dim) for dim in self.dims])\n",
    "        \n",
    "        output_tensor = tf.reduce_mean(output_tensor, axis=0)\n",
    "        print(\"OT shape\")\n",
    "        print(output_tensor.shape)\n",
    "        \n",
    "        # output_tensor = tf.reshape(output_tensor, shape=[-1, rs_input_tensor.shape[1], rs_input_tensor.shape[2], self.output_dim])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return output_tensor\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        FT_Kernel(32, 16, [5, 7]),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Running GK against dim Tensor(\"dim:0\", shape=(), dtype=int32)\n",
      "OT shape\n",
      "(1, 32, 32, 32)\n",
      "[[-0.9157493   1.6831366  -2.5258305   3.4647624   0.98846406 -3.4854643\n",
      "   3.3828075  -0.31854776  2.7687278  -0.8331905 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5947633e-03, 6.1793804e-02, 9.1836171e-04, 3.6702463e-01,\n",
       "        3.0849813e-02, 3.5176295e-04, 3.3814472e-01, 8.3488086e-03,\n",
       "        1.8298319e-01, 4.9901991e-03]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0842812"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OT shape\n",
      "(50, 32, 32, 32)\n",
      "[[[[-0.13123828 -0.13123828 -0.13123828 ... -0.13123828 -0.13123828\n",
      "    -0.13123828]\n",
      "   [-0.1166115  -0.1166115  -0.1166115  ... -0.1166115  -0.1166115\n",
      "    -0.1166115 ]]\n",
      "\n",
      "  [[ 0.88347185  0.88347185  0.88347185 ...  0.88347185  0.88347185\n",
      "     0.88347185]\n",
      "   [ 0.8452387   0.8452387   0.8452387  ...  0.8452387   0.8452387\n",
      "     0.8452387 ]]\n",
      "\n",
      "  [[ 0.2446993   0.2446993   0.2446993  ...  0.2446993   0.2446993\n",
      "     0.2446993 ]\n",
      "   [ 0.26320064  0.26320064  0.26320064 ...  0.26320064  0.26320064\n",
      "     0.26320064]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.1941455  -0.1941455  -0.1941455  ... -0.1941455  -0.1941455\n",
      "    -0.1941455 ]\n",
      "   [-0.14676875 -0.14676875 -0.14676875 ... -0.14676875 -0.14676875\n",
      "    -0.14676875]]\n",
      "\n",
      "  [[-0.09637898 -0.09637898 -0.09637898 ... -0.09637898 -0.09637898\n",
      "    -0.09637898]\n",
      "   [-0.10183135 -0.10183135 -0.10183135 ... -0.10183135 -0.10183135\n",
      "    -0.10183135]]\n",
      "\n",
      "  [[ 0.3593496   0.3593496   0.3593496  ...  0.3593496   0.3593496\n",
      "     0.3593496 ]\n",
      "   [ 0.29144683  0.29144683  0.29144683 ...  0.29144683  0.29144683\n",
      "     0.29144683]]]\n",
      "\n",
      "\n",
      " [[[-0.21810707 -0.21810707 -0.21810707 ... -0.21810707 -0.21810707\n",
      "    -0.21810707]\n",
      "   [-0.20556544 -0.20556544 -0.20556544 ... -0.20556544 -0.20556544\n",
      "    -0.20556544]]\n",
      "\n",
      "  [[ 0.8766006   0.8766006   0.8766006  ...  0.8766006   0.8766006\n",
      "     0.8766006 ]\n",
      "   [ 0.8381429   0.8381429   0.8381429  ...  0.8381429   0.8381429\n",
      "     0.8381429 ]]\n",
      "\n",
      "  [[ 0.2902342   0.2902342   0.2902342  ...  0.2902342   0.2902342\n",
      "     0.2902342 ]\n",
      "   [ 0.30859762  0.30859762  0.30859762 ...  0.30859762  0.30859762\n",
      "     0.30859762]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.21260504 -0.21260504 -0.21260504 ... -0.21260504 -0.21260504\n",
      "    -0.21260504]\n",
      "   [-0.16494314 -0.16494314 -0.16494314 ... -0.16494314 -0.16494314\n",
      "    -0.16494314]]\n",
      "\n",
      "  [[-0.05182164 -0.05182164 -0.05182164 ... -0.05182164 -0.05182164\n",
      "    -0.05182164]\n",
      "   [-0.06475057 -0.06475057 -0.06475057 ... -0.06475057 -0.06475057\n",
      "    -0.06475057]]\n",
      "\n",
      "  [[ 0.37699002  0.37699002  0.37699002 ...  0.37699002  0.37699002\n",
      "     0.37699002]\n",
      "   [ 0.3084791   0.3084791   0.3084791  ...  0.3084791   0.3084791\n",
      "     0.3084791 ]]]\n",
      "\n",
      "\n",
      " [[[-0.16117401 -0.16117401 -0.16117401 ... -0.16117401 -0.16117401\n",
      "    -0.16117401]\n",
      "   [-0.15067896 -0.15067896 -0.15067896 ... -0.15067896 -0.15067896\n",
      "    -0.15067896]]\n",
      "\n",
      "  [[ 0.8205099   0.8205099   0.8205099  ...  0.8205099   0.8205099\n",
      "     0.8205099 ]\n",
      "   [ 0.7810738   0.7810738   0.7810738  ...  0.7810738   0.7810738\n",
      "     0.7810738 ]]\n",
      "\n",
      "  [[ 0.31761026  0.31761026  0.31761026 ...  0.31761026  0.31761026\n",
      "     0.31761026]\n",
      "   [ 0.32904541  0.32904541  0.32904541 ...  0.32904541  0.32904541\n",
      "     0.32904541]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.20665428 -0.20665428 -0.20665428 ... -0.20665428 -0.20665428\n",
      "    -0.20665428]\n",
      "   [-0.162804   -0.162804   -0.162804   ... -0.162804   -0.162804\n",
      "    -0.162804  ]]\n",
      "\n",
      "  [[-0.03768715 -0.03768715 -0.03768715 ... -0.03768715 -0.03768715\n",
      "    -0.03768715]\n",
      "   [-0.05680565 -0.05680565 -0.05680565 ... -0.05680565 -0.05680565\n",
      "    -0.05680565]]\n",
      "\n",
      "  [[ 0.3848861   0.3848861   0.3848861  ...  0.3848861   0.3848861\n",
      "     0.3848861 ]\n",
      "   [ 0.31847417  0.31847417  0.31847417 ...  0.31847417  0.31847417\n",
      "     0.31847417]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(model.layers[0].amplitudes)\n",
    "    predictions=model(x_train[:50])\n",
    "    loss=loss_fn(y_train[:50], predictions)\n",
    "\n",
    "grads = tape.gradient(loss, model.layers[0].amplitudes)\n",
    "print(grads.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11842146\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(grads.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "35712/50000 [====================>.........] - ETA: 57s - loss: 2.5241 - accuracy: 0.0973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-4e3599f3c53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[1;32m    700\u001b[0m             mode, 'end', step, batch_logs)\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cydas/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\b'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    489\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    490\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/mnt/Shelves/LiveProjects/Resources/miniconda3/installation/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # test_kernel = \n",
    "    # test_kernel = tf.keras.layers.Conv2D(142, 5)\n",
    "    model2 = tf.keras.models.Sequential([\n",
    "        FT_Kernel(256, 28, [3, 5, 7, 9]),\n",
    "        FT_Kernel(256, 28, [3, 5, 7, 9]),\n",
    "        FT_Kernel(128, 28, [3, 5, 7, 9]),\n",
    "        # tf.keras.layers.Conv2D(142, 5),\n",
    "        # tf.keras.layers.Conv2D(142, 5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model2.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "    model2.fit(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2(x_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model2.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_5 = test_kernel.get_kernels(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_5_sample = mk_5[:, :, 0, 0]\n",
    "print(mk_5_sample)\n",
    "ax1.matshow(mk_5_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
